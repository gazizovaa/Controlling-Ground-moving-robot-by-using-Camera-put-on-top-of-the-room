# Controlling-Ground-moving-robot-by-using-Camera-put-on-top-of-the-room
Abstract — The goal of this project is to create a robotic system that can use computational methods for image processing to traverse an established path. To determine the robot’s direction, the program uses a web camera mounted on the robot to take frames or images of the captured objects. When colored circles are placed on a cardboard surface, the robot device employs these frames or images to identify them. Next, it determines where these circles are shared. Following that, the left and right motors of the robot discover how fast they must move forward in order to follow the desired path, due to a control algorithm. Through the Bluetooth communication with the  robot, both linear and angular velocities are sent to the robot.Furthermore, this report outlines the robotic system’s architecture, implementation, testing, design concept and illustrates how to trace the desired path in a variety of scenarios. 

Keywords-component: computer vision, image segmentation, ground-moving robot, image processing, control algorithms

## I. Introduction
_A. Definition_

The project embraces a list of essential concepts applied by our team while creating a program using Open Source Computer Vision library Python(OpenCV). When images are analyzed and modified using computational algorithms, this process is known as “image processing”. In particular, it entails the robot’s detection and recognition of colored circles placed on a cardboard surface. Next, the term used to control the robot’s movement, named “control algorithm” refers to the set of instructions or logic. The analysis of them forms the basis of the movement. This algorithm computes the robot’s trajectory along a predefined path to guarantee that the robot moves in the desired path. Along with this, it retains the stability. Furthermore, the central position, or coordinates of the detected and colored circles on the cardboard is indicated by the term “central point”. The term “path” refers to the established track that gives directions to the robot to follow. The motors are mechanical components that drive the robot’s movement, and signals are sent to them to control the speeds of both left and right motors. Moreover, Bluetooth permits wireless communication between the motors and the robot’s control system, which is referred to as “embot”. A key part of this project’s image processing workflow is to study the capability of OpenCV library to read images straight from the web camera. Thus, it is also vital to distinguish the colors’ centers individually. Furthermore, smoothing techniques, such as spline interpolation are applied to improve the smoothness of the user-defined trajectory. In this way, the constant movement of the robot is assured. Thus, the data points that the user clicks are used to calculate the interpolated trajectory. Next, for the purpose of moving the robot, its kinematics model transforms desired linear and angular velocities through wheel velocities. The velocities of both left and right wheels in the robot have been adjusted by this model to the desired velocities. Then, we have included a few created functions in our program that apply the HSV color space to detect colors, red and blue ones, in the video. By this way, we have been identified with the direction and position of the robot. 

_B. Purpose_

Combining closed-loop control and computational image processing, our project desired to deliver a reliable and effective trajectory-following program for mobile robots. The principal aim is to facilitate a robot’s ability to precisely and error-free trace an established path. In essence, the system guarantees accurate navigation along the designated path through applying image processing techniques to track the position and direction of the robot. In addition, with this project, we believe to boost the accessibility and dependability of mobile robots, so they can function successfully in a variety of settings. Accordingly, when cardboard is placed on a robot in a direction, which we mean, it turns white and allows for the  application of two different colored circles. After an image is taken from above by the web camera and sent to the computer (as though it were connected to the web camera), image processing takes place. Prior to finding their common point, we ust first identify two colored circles. To control the robot through looking up, we need to use image processing to  determine the circle’s center and direction to be processed along the path that has been given to us. We consider an error if the robot moves in both directions. The next step is to determine the appropriate speeds for the left and right motors based on the desired path, and control algorithm. Subsequently, we transmit it to the robot, which assuming it is equipped with Bluetooth, transmits those signals to the motors. The robot’s only function in this situation is to use Bluetooth to obtain the motors’ speed data. 
                                                                                                                       





